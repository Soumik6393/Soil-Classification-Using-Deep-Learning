{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c1c0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Conv2D,MaxPool2D,ZeroPadding2D,GlobalAveragePooling2D,AveragePooling2D\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Add,Activation,concatenate,Input\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from keras.preprocessing import image\n",
    "gpus=tf.config.experimental.list_physical_devices('GPU') \n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99aa0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Data\n",
    "train_dir=r'C:\\Users\\soumi\\OneDrive\\Desktop\\Project_sample\\train_dir'\n",
    "test_dir=r'C:\\Users\\soumi\\OneDrive\\Desktop\\Project_sample\\test_dir'\n",
    "valid_dir=r'C:\\Users\\soumi\\OneDrive\\Desktop\\Project_sample\\test_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bc9fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescaling and augmentation of data\n",
    "data_augmentation=tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\",input_shape=(224,224,3)),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomWidth(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "],name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5fae290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 files belonging to 10 classes.\n",
      "Found 57 files belonging to 10 classes.\n",
      "Found 57 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE=(224,224)\n",
    "BATCH_SIZE=32\n",
    "training_set=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory = test_dir,\n",
    "    image_size = IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode = 'categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "validation_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory = valid_dir,\n",
    "    image_size = IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode = 'categorical',\n",
    ")\n",
    "class_names=validation_set.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4d144d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x,filters,row,col,padding='same',strides=(1,1)):\n",
    "    x=Conv2D(filters,(row,col),strides=strides,padding=padding)(x)\n",
    "    x=BatchNormalization(axis=3)(x)\n",
    "    x=Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50b635eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_a(x):\n",
    "    c1x1=conv_bn(x,64,1,1)\n",
    "    c3x3=conv_bn(x,48,1,1)\n",
    "    c3x3=conv_bn(c3x3,64,3,3)\n",
    "    c5x5=conv_bn(x,64,1,1)\n",
    "    c5x5=conv_bn(c5x5,96,3,3)\n",
    "    c5x5=conv_bn(c5x5,96,3,3)\n",
    "    mpool=MaxPool2D(pool_size=(3,3),strides=(1,1),padding='same')(x)\n",
    "    mpool=conv_bn(mpool,32,1,1)\n",
    "    x=concatenate([c1x1,c3x3,c5x5,mpool],axis=3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6287fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_block_a(x):\n",
    "    mpool=MaxPool2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "    c3x3=conv_bn(x,384,3,3,strides=(2,2),padding='valid')\n",
    "    c1_3x3=conv_bn(x,64,1,1)\n",
    "    c1_3x3=conv_bn(c1_3x3,96,3,3)\n",
    "    c1_3x3=conv_bn(c1_3x3,96,3,3,strides=(2,2),padding='valid')\n",
    "    x=concatenate([mpool,c3x3,c1_3x3])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3f52e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_b(x):\n",
    "    c1x1=conv_bn(x,192,1,1)\n",
    "    c_b1=AveragePooling2D(pool_size=(3,3),strides=(1,1),padding='same')(x)\n",
    "    c_b1=conv_bn(c_b1,192,1,1)\n",
    "    c_b2=conv_bn(x,128,1,1)\n",
    "    c_b2=conv_bn(c_b2,128,1,7)\n",
    "    c_b2=conv_bn(c_b2,192,7,1)\n",
    "    c_b3=conv_bn(x,128,1,1)\n",
    "    c_b3=conv_bn(c_b3,128,7,1)\n",
    "    c_b3=conv_bn(c_b3,128,1,7)\n",
    "    c_b3=conv_bn(c_b3,128,7,1)\n",
    "    c_b3=conv_bn(c_b3,192,1,7)\n",
    "    x=concatenate([c1x1,c_b1,c_b2,c_b3],axis=3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae74bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_block_b(x):\n",
    "    b1=MaxPool2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "    b2=conv_bn(x,192,1,1)\n",
    "    b2=conv_bn(b2,320,3,3,strides=(2,2),padding='valid')\n",
    "    b3=conv_bn(x,192,1,1)\n",
    "    b3=conv_bn(b3,192,1,7)\n",
    "    b3=conv_bn(b3,192,7,1)\n",
    "    b3=conv_bn(b3,192,3,3,strides=(2,2),padding='valid')\n",
    "    x=concatenate([b1,b2,b3],axis=3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e82f71cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_c(x):\n",
    "    b1=conv_bn(x,320,1,1)\n",
    "    b2=conv_bn(x,384,1,1)\n",
    "    b2_1x3=conv_bn(b2,384,1,3)\n",
    "    b2_3x1=conv_bn(b2,384,3,1)\n",
    "    b2=concatenate([b2_1x3,b2_3x1],axis=3)\n",
    "    b3=conv_bn(x,448,1,1)\n",
    "    b3_3x3=conv_bn(b3,384,3,3)\n",
    "    b3_1x3=conv_bn(b3_3x3,384,1,3)\n",
    "    b3_3x1=conv_bn(b3_3x3,384,3,1)\n",
    "    b3=concatenate([b3_1x3,b2_3x1],axis=3)\n",
    "    b4=AveragePooling2D((3,3),strides=(1,1),padding='same')(x)\n",
    "    b4=conv_bn(b4,192,1,1)\n",
    "    x=concatenate([b1,b2,b3,b4],axis=3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27d39f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inceptionv3(input_shape=(224,224,3),classes=10):\n",
    "    img_input=Input(input_shape)\n",
    "    \n",
    "    x=conv_bn(img_input,32,3,3,padding='valid',strides=(2,2))\n",
    "    x=conv_bn(x,32,3,3,padding='valid')\n",
    "    x=conv_bn(x,64,3,3)\n",
    "    x=MaxPool2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "\n",
    "    x=inc_block_a(x)\n",
    "    x=inc_block_a(x)\n",
    "    x=inc_block_a(x)\n",
    "\n",
    "    x=reduction_block_a(x)\n",
    "\n",
    "    x=inc_block_b(x)\n",
    "    x=inc_block_b(x)\n",
    "    x=inc_block_b(x)\n",
    "    x=inc_block_b(x)\n",
    "\n",
    "    x=reduction_block_b(x) \n",
    "    \n",
    "    x=inc_block_c(x)\n",
    "\n",
    "    x=inc_block_c(x)\n",
    "\n",
    "    x=GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "    x=Flatten()(x)\n",
    "\n",
    "    x=Dense(units=2048,activation='relu')(x)\n",
    "\n",
    "    x=Dense(units=classes,activation='softmax',name='predictions')(x)\n",
    "\n",
    "    model=Model(img_input,x,name='Inceptionv3')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9093a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Inceptionv3(input_shape=(224,224,3),classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75e7259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#Checkpoint to save the best model per epoch\n",
    "model_path=r'C:\\Users\\soumi\\OneDrive\\Desktop\\Inceptionv3\\Inc{epoch:02d}-{val_accuracy:.4f}.hdf5'\n",
    "checkpoint=ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf8e1872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Inceptionv3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_184 (Conv2D)         (None, 111, 111, 32)         896       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_184 (B  (None, 111, 111, 32)         128       ['conv2d_184[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_184 (Activation  (None, 111, 111, 32)         0         ['batch_normalization_184[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_185 (Conv2D)         (None, 109, 109, 32)         9248      ['activation_184[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_185 (B  (None, 109, 109, 32)         128       ['conv2d_185[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_185 (Activation  (None, 109, 109, 32)         0         ['batch_normalization_185[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_186 (Conv2D)         (None, 109, 109, 64)         18496     ['activation_185[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_186 (B  (None, 109, 109, 64)         256       ['conv2d_186[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_186 (Activation  (None, 109, 109, 64)         0         ['batch_normalization_186[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooli  (None, 54, 54, 64)           0         ['activation_186[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)         (None, 54, 54, 64)           4160      ['max_pooling2d_12[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_190 (B  (None, 54, 54, 64)           256       ['conv2d_190[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_190 (Activation  (None, 54, 54, 64)           0         ['batch_normalization_190[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)         (None, 54, 54, 48)           3120      ['max_pooling2d_12[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)         (None, 54, 54, 96)           55392     ['activation_190[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_188 (B  (None, 54, 54, 48)           192       ['conv2d_188[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_191 (B  (None, 54, 54, 96)           384       ['conv2d_191[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_188 (Activation  (None, 54, 54, 48)           0         ['batch_normalization_188[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_191 (Activation  (None, 54, 54, 96)           0         ['batch_normalization_191[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooli  (None, 54, 54, 64)           0         ['max_pooling2d_12[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_187 (Conv2D)         (None, 54, 54, 64)           4160      ['max_pooling2d_12[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)         (None, 54, 54, 64)           27712     ['activation_188[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)         (None, 54, 54, 96)           83040     ['activation_191[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)         (None, 54, 54, 32)           2080      ['max_pooling2d_13[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_187 (B  (None, 54, 54, 64)           256       ['conv2d_187[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_189 (B  (None, 54, 54, 64)           256       ['conv2d_189[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_192 (B  (None, 54, 54, 96)           384       ['conv2d_192[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_193 (B  (None, 54, 54, 32)           128       ['conv2d_193[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_187 (Activation  (None, 54, 54, 64)           0         ['batch_normalization_187[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_189 (Activation  (None, 54, 54, 64)           0         ['batch_normalization_189[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_192 (Activation  (None, 54, 54, 96)           0         ['batch_normalization_192[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_193 (Activation  (None, 54, 54, 32)           0         ['batch_normalization_193[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenat  (None, 54, 54, 256)          0         ['activation_187[0][0]',      \n",
      " e)                                                                  'activation_189[0][0]',      \n",
      "                                                                     'activation_192[0][0]',      \n",
      "                                                                     'activation_193[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)         (None, 54, 54, 64)           16448     ['concatenate_30[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_197 (B  (None, 54, 54, 64)           256       ['conv2d_197[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_197 (Activation  (None, 54, 54, 64)           0         ['batch_normalization_197[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)         (None, 54, 54, 48)           12336     ['concatenate_30[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)         (None, 54, 54, 96)           55392     ['activation_197[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_195 (B  (None, 54, 54, 48)           192       ['conv2d_195[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_198 (B  (None, 54, 54, 96)           384       ['conv2d_198[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_195 (Activation  (None, 54, 54, 48)           0         ['batch_normalization_195[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_198 (Activation  (None, 54, 54, 96)           0         ['batch_normalization_198[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooli  (None, 54, 54, 256)          0         ['concatenate_30[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)         (None, 54, 54, 64)           16448     ['concatenate_30[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)         (None, 54, 54, 64)           27712     ['activation_195[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)         (None, 54, 54, 96)           83040     ['activation_198[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)         (None, 54, 54, 32)           8224      ['max_pooling2d_14[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_194 (B  (None, 54, 54, 64)           256       ['conv2d_194[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_196 (B  (None, 54, 54, 64)           256       ['conv2d_196[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_199 (B  (None, 54, 54, 96)           384       ['conv2d_199[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_200 (B  (None, 54, 54, 32)           128       ['conv2d_200[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_194 (Activation  (None, 54, 54, 64)           0         ['batch_normalization_194[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_196 (Activation  (None, 54, 54, 64)           0         ['batch_normalization_196[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_199 (Activation  (None, 54, 54, 96)           0         ['batch_normalization_199[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_200 (Activation  (None, 54, 54, 32)           0         ['batch_normalization_200[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenat  (None, 54, 54, 256)          0         ['activation_194[0][0]',      \n",
      " e)                                                                  'activation_196[0][0]',      \n",
      "                                                                     'activation_199[0][0]',      \n",
      "                                                                     'activation_200[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_204 (Conv2D)         (None, 54, 54, 64)           16448     ['concatenate_31[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_204 (B  (None, 54, 54, 64)           256       ['conv2d_204[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_204 (Activation  (None, 54, 54, 64)           0         ['batch_normalization_204[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_202 (Conv2D)         (None, 54, 54, 48)           12336     ['concatenate_31[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_205 (Conv2D)         (None, 54, 54, 96)           55392     ['activation_204[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_202 (B  (None, 54, 54, 48)           192       ['conv2d_202[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_205 (B  (None, 54, 54, 96)           384       ['conv2d_205[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_202 (Activation  (None, 54, 54, 48)           0         ['batch_normalization_202[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_205 (Activation  (None, 54, 54, 96)           0         ['batch_normalization_205[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_15 (MaxPooli  (None, 54, 54, 256)          0         ['concatenate_31[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)         (None, 54, 54, 64)           16448     ['concatenate_31[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_203 (Conv2D)         (None, 54, 54, 64)           27712     ['activation_202[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_206 (Conv2D)         (None, 54, 54, 96)           83040     ['activation_205[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_207 (Conv2D)         (None, 54, 54, 32)           8224      ['max_pooling2d_15[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_201 (B  (None, 54, 54, 64)           256       ['conv2d_201[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_203 (B  (None, 54, 54, 64)           256       ['conv2d_203[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_206 (B  (None, 54, 54, 96)           384       ['conv2d_206[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_207 (B  (None, 54, 54, 32)           128       ['conv2d_207[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_201 (Activation  (None, 54, 54, 64)           0         ['batch_normalization_201[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_203 (Activation  (None, 54, 54, 64)           0         ['batch_normalization_203[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_206 (Activation  (None, 54, 54, 96)           0         ['batch_normalization_206[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_207 (Activation  (None, 54, 54, 32)           0         ['batch_normalization_207[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenat  (None, 54, 54, 256)          0         ['activation_201[0][0]',      \n",
      " e)                                                                  'activation_203[0][0]',      \n",
      "                                                                     'activation_206[0][0]',      \n",
      "                                                                     'activation_207[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)         (None, 54, 54, 64)           16448     ['concatenate_32[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_209 (B  (None, 54, 54, 64)           256       ['conv2d_209[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_209 (Activation  (None, 54, 54, 64)           0         ['batch_normalization_209[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)         (None, 54, 54, 96)           55392     ['activation_209[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_210 (B  (None, 54, 54, 96)           384       ['conv2d_210[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_210 (Activation  (None, 54, 54, 96)           0         ['batch_normalization_210[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_208 (Conv2D)         (None, 26, 26, 384)          885120    ['concatenate_32[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)         (None, 26, 26, 96)           83040     ['activation_210[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_208 (B  (None, 26, 26, 384)          1536      ['conv2d_208[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_211 (B  (None, 26, 26, 96)           384       ['conv2d_211[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_16 (MaxPooli  (None, 26, 26, 256)          0         ['concatenate_32[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " activation_208 (Activation  (None, 26, 26, 384)          0         ['batch_normalization_208[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_211 (Activation  (None, 26, 26, 96)           0         ['batch_normalization_211[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenat  (None, 26, 26, 736)          0         ['max_pooling2d_16[0][0]',    \n",
      " e)                                                                  'activation_208[0][0]',      \n",
      "                                                                     'activation_211[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)         (None, 26, 26, 128)          94336     ['concatenate_33[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_217 (B  (None, 26, 26, 128)          512       ['conv2d_217[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_217 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_217[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_217[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_218 (B  (None, 26, 26, 128)          512       ['conv2d_218[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_218 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_218[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)         (None, 26, 26, 128)          94336     ['concatenate_33[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_218[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_214 (B  (None, 26, 26, 128)          512       ['conv2d_214[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_219 (B  (None, 26, 26, 128)          512       ['conv2d_219[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_214 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_214[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_219 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_219[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_214[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_219[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_215 (B  (None, 26, 26, 128)          512       ['conv2d_215[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_220 (B  (None, 26, 26, 128)          512       ['conv2d_220[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " average_pooling2d_12 (Aver  (None, 26, 26, 736)          0         ['concatenate_33[0][0]']      \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " activation_215 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_215[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_220 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_220[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)         (None, 26, 26, 192)          141504    ['concatenate_33[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)         (None, 26, 26, 192)          141504    ['average_pooling2d_12[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)         (None, 26, 26, 192)          172224    ['activation_215[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)         (None, 26, 26, 192)          172224    ['activation_220[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_212 (B  (None, 26, 26, 192)          768       ['conv2d_212[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_213 (B  (None, 26, 26, 192)          768       ['conv2d_213[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_216 (B  (None, 26, 26, 192)          768       ['conv2d_216[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_221 (B  (None, 26, 26, 192)          768       ['conv2d_221[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_212 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_212[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_213 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_213[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_216 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_216[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_221 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_221[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenat  (None, 26, 26, 768)          0         ['activation_212[0][0]',      \n",
      " e)                                                                  'activation_213[0][0]',      \n",
      "                                                                     'activation_216[0][0]',      \n",
      "                                                                     'activation_221[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)         (None, 26, 26, 128)          98432     ['concatenate_34[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_227 (B  (None, 26, 26, 128)          512       ['conv2d_227[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_227 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_227[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_227[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_228 (B  (None, 26, 26, 128)          512       ['conv2d_228[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_228 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_228[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)         (None, 26, 26, 128)          98432     ['concatenate_34[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_228[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_224 (B  (None, 26, 26, 128)          512       ['conv2d_224[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_229 (B  (None, 26, 26, 128)          512       ['conv2d_229[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_224 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_224[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_229 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_229[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_224[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_229[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_225 (B  (None, 26, 26, 128)          512       ['conv2d_225[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_230 (B  (None, 26, 26, 128)          512       ['conv2d_230[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " average_pooling2d_13 (Aver  (None, 26, 26, 768)          0         ['concatenate_34[0][0]']      \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " activation_225 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_225[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_230 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_230[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)         (None, 26, 26, 192)          147648    ['concatenate_34[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)         (None, 26, 26, 192)          147648    ['average_pooling2d_13[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)         (None, 26, 26, 192)          172224    ['activation_225[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)         (None, 26, 26, 192)          172224    ['activation_230[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_222 (B  (None, 26, 26, 192)          768       ['conv2d_222[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_223 (B  (None, 26, 26, 192)          768       ['conv2d_223[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_226 (B  (None, 26, 26, 192)          768       ['conv2d_226[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_231 (B  (None, 26, 26, 192)          768       ['conv2d_231[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_222 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_222[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_223 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_223[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_226 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_226[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_231 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_231[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenat  (None, 26, 26, 768)          0         ['activation_222[0][0]',      \n",
      " e)                                                                  'activation_223[0][0]',      \n",
      "                                                                     'activation_226[0][0]',      \n",
      "                                                                     'activation_231[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)         (None, 26, 26, 128)          98432     ['concatenate_35[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_237 (B  (None, 26, 26, 128)          512       ['conv2d_237[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_237 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_237[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_237[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_238 (B  (None, 26, 26, 128)          512       ['conv2d_238[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_238 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_238[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)         (None, 26, 26, 128)          98432     ['concatenate_35[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_238[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_234 (B  (None, 26, 26, 128)          512       ['conv2d_234[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_239 (B  (None, 26, 26, 128)          512       ['conv2d_239[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_234 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_234[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_239 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_239[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_234[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_239[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_235 (B  (None, 26, 26, 128)          512       ['conv2d_235[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_240 (B  (None, 26, 26, 128)          512       ['conv2d_240[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " average_pooling2d_14 (Aver  (None, 26, 26, 768)          0         ['concatenate_35[0][0]']      \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " activation_235 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_235[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_240 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_240[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)         (None, 26, 26, 192)          147648    ['concatenate_35[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)         (None, 26, 26, 192)          147648    ['average_pooling2d_14[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)         (None, 26, 26, 192)          172224    ['activation_235[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)         (None, 26, 26, 192)          172224    ['activation_240[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_232 (B  (None, 26, 26, 192)          768       ['conv2d_232[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_233 (B  (None, 26, 26, 192)          768       ['conv2d_233[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_236 (B  (None, 26, 26, 192)          768       ['conv2d_236[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_241 (B  (None, 26, 26, 192)          768       ['conv2d_241[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_232 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_232[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_233 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_233[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_236 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_236[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_241 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_241[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenat  (None, 26, 26, 768)          0         ['activation_232[0][0]',      \n",
      " e)                                                                  'activation_233[0][0]',      \n",
      "                                                                     'activation_236[0][0]',      \n",
      "                                                                     'activation_241[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)         (None, 26, 26, 128)          98432     ['concatenate_36[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_247 (B  (None, 26, 26, 128)          512       ['conv2d_247[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_247 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_247[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_247[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_248 (B  (None, 26, 26, 128)          512       ['conv2d_248[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_248 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_248[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)         (None, 26, 26, 128)          98432     ['concatenate_36[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_248[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_244 (B  (None, 26, 26, 128)          512       ['conv2d_244[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_249 (B  (None, 26, 26, 128)          512       ['conv2d_249[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_244 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_244[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_249 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_249[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_244[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)         (None, 26, 26, 128)          114816    ['activation_249[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_245 (B  (None, 26, 26, 128)          512       ['conv2d_245[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_250 (B  (None, 26, 26, 128)          512       ['conv2d_250[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " average_pooling2d_15 (Aver  (None, 26, 26, 768)          0         ['concatenate_36[0][0]']      \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " activation_245 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_245[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_250 (Activation  (None, 26, 26, 128)          0         ['batch_normalization_250[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)         (None, 26, 26, 192)          147648    ['concatenate_36[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)         (None, 26, 26, 192)          147648    ['average_pooling2d_15[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)         (None, 26, 26, 192)          172224    ['activation_245[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)         (None, 26, 26, 192)          172224    ['activation_250[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_242 (B  (None, 26, 26, 192)          768       ['conv2d_242[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_243 (B  (None, 26, 26, 192)          768       ['conv2d_243[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_246 (B  (None, 26, 26, 192)          768       ['conv2d_246[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_251 (B  (None, 26, 26, 192)          768       ['conv2d_251[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_242 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_242[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_243 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_243[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_246 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_246[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_251 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_251[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenat  (None, 26, 26, 768)          0         ['activation_242[0][0]',      \n",
      " e)                                                                  'activation_243[0][0]',      \n",
      "                                                                     'activation_246[0][0]',      \n",
      "                                                                     'activation_251[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)         (None, 26, 26, 192)          147648    ['concatenate_37[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_254 (B  (None, 26, 26, 192)          768       ['conv2d_254[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_254 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_254[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)         (None, 26, 26, 192)          258240    ['activation_254[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_255 (B  (None, 26, 26, 192)          768       ['conv2d_255[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_255 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_255[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)         (None, 26, 26, 192)          147648    ['concatenate_37[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)         (None, 26, 26, 192)          258240    ['activation_255[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_252 (B  (None, 26, 26, 192)          768       ['conv2d_252[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_256 (B  (None, 26, 26, 192)          768       ['conv2d_256[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_252 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_252[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_256 (Activation  (None, 26, 26, 192)          0         ['batch_normalization_256[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)         (None, 12, 12, 320)          553280    ['activation_252[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)         (None, 12, 12, 192)          331968    ['activation_256[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_253 (B  (None, 12, 12, 320)          1280      ['conv2d_253[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_257 (B  (None, 12, 12, 192)          768       ['conv2d_257[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_17 (MaxPooli  (None, 12, 12, 768)          0         ['concatenate_37[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " activation_253 (Activation  (None, 12, 12, 320)          0         ['batch_normalization_253[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_257 (Activation  (None, 12, 12, 192)          0         ['batch_normalization_257[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_38 (Concatenat  (None, 12, 12, 1280)         0         ['max_pooling2d_17[0][0]',    \n",
      " e)                                                                  'activation_253[0][0]',      \n",
      "                                                                     'activation_257[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)         (None, 12, 12, 448)          573888    ['concatenate_38[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_262 (B  (None, 12, 12, 448)          1792      ['conv2d_262[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_262 (Activation  (None, 12, 12, 448)          0         ['batch_normalization_262[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)         (None, 12, 12, 384)          491904    ['concatenate_38[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)         (None, 12, 12, 384)          1548672   ['activation_262[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_259 (B  (None, 12, 12, 384)          1536      ['conv2d_259[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_263 (B  (None, 12, 12, 384)          1536      ['conv2d_263[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_259 (Activation  (None, 12, 12, 384)          0         ['batch_normalization_259[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_263 (Activation  (None, 12, 12, 384)          0         ['batch_normalization_263[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)         (None, 12, 12, 384)          442752    ['activation_259[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)         (None, 12, 12, 384)          442752    ['activation_259[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)         (None, 12, 12, 384)          442752    ['activation_263[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling2d_16 (Aver  (None, 12, 12, 1280)         0         ['concatenate_38[0][0]']      \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_258 (Conv2D)         (None, 12, 12, 320)          409920    ['concatenate_38[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_260 (B  (None, 12, 12, 384)          1536      ['conv2d_260[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_261 (B  (None, 12, 12, 384)          1536      ['conv2d_261[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_264 (B  (None, 12, 12, 384)          1536      ['conv2d_264[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)         (None, 12, 12, 192)          245952    ['average_pooling2d_16[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_258 (B  (None, 12, 12, 320)          1280      ['conv2d_258[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_260 (Activation  (None, 12, 12, 384)          0         ['batch_normalization_260[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_261 (Activation  (None, 12, 12, 384)          0         ['batch_normalization_261[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_264 (Activation  (None, 12, 12, 384)          0         ['batch_normalization_264[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_266 (B  (None, 12, 12, 192)          768       ['conv2d_266[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_258 (Activation  (None, 12, 12, 320)          0         ['batch_normalization_258[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenat  (None, 12, 12, 768)          0         ['activation_260[0][0]',      \n",
      " e)                                                                  'activation_261[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_40 (Concatenat  (None, 12, 12, 768)          0         ['activation_264[0][0]',      \n",
      " e)                                                                  'activation_261[0][0]']      \n",
      "                                                                                                  \n",
      " activation_266 (Activation  (None, 12, 12, 192)          0         ['batch_normalization_266[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenat  (None, 12, 12, 2048)         0         ['activation_258[0][0]',      \n",
      " e)                                                                  'concatenate_39[0][0]',      \n",
      "                                                                     'concatenate_40[0][0]',      \n",
      "                                                                     'activation_266[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)         (None, 12, 12, 448)          917952    ['concatenate_41[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_271 (B  (None, 12, 12, 448)          1792      ['conv2d_271[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_271 (Activation  (None, 12, 12, 448)          0         ['batch_normalization_271[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)         (None, 12, 12, 384)          786816    ['concatenate_41[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)         (None, 12, 12, 384)          1548672   ['activation_271[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_268 (B  (None, 12, 12, 384)          1536      ['conv2d_268[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_272 (B  (None, 12, 12, 384)          1536      ['conv2d_272[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_268 (Activation  (None, 12, 12, 384)          0         ['batch_normalization_268[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_272 (Activation  (None, 12, 12, 384)          0         ['batch_normalization_272[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)         (None, 12, 12, 384)          442752    ['activation_268[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)         (None, 12, 12, 384)          442752    ['activation_268[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)         (None, 12, 12, 384)          442752    ['activation_272[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling2d_17 (Aver  (None, 12, 12, 2048)         0         ['concatenate_41[0][0]']      \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)         (None, 12, 12, 320)          655680    ['concatenate_41[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_269 (B  (None, 12, 12, 384)          1536      ['conv2d_269[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_270 (B  (None, 12, 12, 384)          1536      ['conv2d_270[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_273 (B  (None, 12, 12, 384)          1536      ['conv2d_273[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)         (None, 12, 12, 192)          393408    ['average_pooling2d_17[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_267 (B  (None, 12, 12, 320)          1280      ['conv2d_267[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_269 (Activation  (None, 12, 12, 384)          0         ['batch_normalization_269[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_270 (Activation  (None, 12, 12, 384)          0         ['batch_normalization_270[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_273 (Activation  (None, 12, 12, 384)          0         ['batch_normalization_273[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_275 (B  (None, 12, 12, 192)          768       ['conv2d_275[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_267 (Activation  (None, 12, 12, 320)          0         ['batch_normalization_267[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenat  (None, 12, 12, 768)          0         ['activation_269[0][0]',      \n",
      " e)                                                                  'activation_270[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenat  (None, 12, 12, 768)          0         ['activation_273[0][0]',      \n",
      " e)                                                                  'activation_270[0][0]']      \n",
      "                                                                                                  \n",
      " activation_275 (Activation  (None, 12, 12, 192)          0         ['batch_normalization_275[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_44 (Concatenat  (None, 12, 12, 2048)         0         ['activation_267[0][0]',      \n",
      " e)                                                                  'concatenate_42[0][0]',      \n",
      "                                                                     'concatenate_43[0][0]',      \n",
      "                                                                     'activation_275[0][0]']      \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePoo  (None, 2048)                 0         ['concatenate_44[0][0]']      \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 2048)                 0         ['avg_pool[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 2048)                 4196352   ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " predictions (Dense)         (None, 10)                   20490     ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23055130 (87.95 MB)\n",
      "Trainable params: 23024442 (87.83 MB)\n",
      "Non-trainable params: 30688 (119.88 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d17e20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af9b73ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.1041 - accuracy: 0.5762 \n",
      "Epoch 1: val_loss did not improve from 54.38263\n",
      "7/7 [==============================] - 183s 25s/step - loss: 1.1041 - accuracy: 0.5762 - val_loss: 95.7577 - val_accuracy: 0.2807\n",
      "Epoch 2/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.9874 - accuracy: 0.6143 \n",
      "Epoch 2: val_loss did not improve from 54.38263\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.9874 - accuracy: 0.6143 - val_loss: 174.6904 - val_accuracy: 0.2281\n",
      "Epoch 3/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.9759 - accuracy: 0.6333 \n",
      "Epoch 3: val_loss did not improve from 54.38263\n",
      "7/7 [==============================] - 180s 25s/step - loss: 0.9759 - accuracy: 0.6333 - val_loss: 59.5333 - val_accuracy: 0.2982\n",
      "Epoch 4/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.0095 - accuracy: 0.6143 \n",
      "Epoch 4: val_loss improved from 54.38263 to 34.39356, saving model to C:\\Users\\soumi\\OneDrive\\Desktop\\Inceptionv3\\Inc04-0.2807.hdf5\n",
      "7/7 [==============================] - 184s 26s/step - loss: 1.0095 - accuracy: 0.6143 - val_loss: 34.3936 - val_accuracy: 0.2807\n",
      "Epoch 5/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.9716 - accuracy: 0.6667 \n",
      "Epoch 5: val_loss improved from 34.39356 to 18.16333, saving model to C:\\Users\\soumi\\OneDrive\\Desktop\\Inceptionv3\\Inc05-0.2807.hdf5\n",
      "7/7 [==============================] - 183s 26s/step - loss: 0.9716 - accuracy: 0.6667 - val_loss: 18.1633 - val_accuracy: 0.2807\n",
      "Epoch 6/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.4876 - accuracy: 0.5238 \n",
      "Epoch 6: val_loss did not improve from 18.16333\n",
      "7/7 [==============================] - 180s 25s/step - loss: 1.4876 - accuracy: 0.5238 - val_loss: 70.4260 - val_accuracy: 0.3158\n",
      "Epoch 7/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.1854 - accuracy: 0.5714 \n",
      "Epoch 7: val_loss did not improve from 18.16333\n",
      "7/7 [==============================] - 179s 25s/step - loss: 1.1854 - accuracy: 0.5714 - val_loss: 18.5810 - val_accuracy: 0.2982\n",
      "Epoch 8/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.2445 - accuracy: 0.5857 \n",
      "Epoch 8: val_loss improved from 18.16333 to 6.71395, saving model to C:\\Users\\soumi\\OneDrive\\Desktop\\Inceptionv3\\Inc08-0.1754.hdf5\n",
      "7/7 [==============================] - 182s 25s/step - loss: 1.2445 - accuracy: 0.5857 - val_loss: 6.7140 - val_accuracy: 0.1754\n",
      "Epoch 9/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.0315 - accuracy: 0.6000 \n",
      "Epoch 9: val_loss improved from 6.71395 to 3.40825, saving model to C:\\Users\\soumi\\OneDrive\\Desktop\\Inceptionv3\\Inc09-0.3333.hdf5\n",
      "7/7 [==============================] - 183s 26s/step - loss: 1.0315 - accuracy: 0.6000 - val_loss: 3.4082 - val_accuracy: 0.3333\n",
      "Epoch 10/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.0173 - accuracy: 0.6238 \n",
      "Epoch 10: val_loss did not improve from 3.40825\n",
      "7/7 [==============================] - 180s 25s/step - loss: 1.0173 - accuracy: 0.6238 - val_loss: 5.2168 - val_accuracy: 0.2982\n",
      "Epoch 11/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.0207 - accuracy: 0.6476 \n",
      "Epoch 11: val_loss did not improve from 3.40825\n",
      "7/7 [==============================] - 181s 25s/step - loss: 1.0207 - accuracy: 0.6476 - val_loss: 9.6146 - val_accuracy: 0.4035\n",
      "Epoch 12/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8774 - accuracy: 0.7000 \n",
      "Epoch 12: val_loss did not improve from 3.40825\n",
      "7/7 [==============================] - 179s 25s/step - loss: 0.8774 - accuracy: 0.7000 - val_loss: 6.9213 - val_accuracy: 0.3158\n",
      "Epoch 13/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8662 - accuracy: 0.7000 \n",
      "Epoch 13: val_loss did not improve from 3.40825\n",
      "7/7 [==============================] - 180s 25s/step - loss: 0.8662 - accuracy: 0.7000 - val_loss: 11.2351 - val_accuracy: 0.3509\n",
      "Epoch 14/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8570 - accuracy: 0.6905 \n",
      "Epoch 14: val_loss did not improve from 3.40825\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.8570 - accuracy: 0.6905 - val_loss: 14.5314 - val_accuracy: 0.2982\n",
      "Epoch 15/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.0477 - accuracy: 0.6286 \n",
      "Epoch 15: val_loss did not improve from 3.40825\n",
      "7/7 [==============================] - 153s 20s/step - loss: 1.0477 - accuracy: 0.6286 - val_loss: 6.6059 - val_accuracy: 0.3860\n",
      "Epoch 16/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.9102 - accuracy: 0.6381 \n",
      "Epoch 16: val_loss improved from 3.40825 to 3.20403, saving model to C:\\Users\\soumi\\OneDrive\\Desktop\\Inceptionv3\\Inc16-0.3860.hdf5\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.9102 - accuracy: 0.6381 - val_loss: 3.2040 - val_accuracy: 0.3860\n",
      "Epoch 17/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8211 - accuracy: 0.7238 \n",
      "Epoch 17: val_loss did not improve from 3.20403\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.8211 - accuracy: 0.7238 - val_loss: 4.1098 - val_accuracy: 0.2281\n",
      "Epoch 18/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8097 - accuracy: 0.6810 \n",
      "Epoch 18: val_loss did not improve from 3.20403\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.8097 - accuracy: 0.6810 - val_loss: 4.3658 - val_accuracy: 0.4561\n",
      "Epoch 19/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6783 - accuracy: 0.7571 \n",
      "Epoch 19: val_loss did not improve from 3.20403\n",
      "7/7 [==============================] - 160s 23s/step - loss: 0.6783 - accuracy: 0.7571 - val_loss: 5.2562 - val_accuracy: 0.3684\n",
      "Epoch 20/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6738 - accuracy: 0.7476 \n",
      "Epoch 20: val_loss did not improve from 3.20403\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.6738 - accuracy: 0.7476 - val_loss: 4.8682 - val_accuracy: 0.4035\n",
      "Epoch 21/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8194 - accuracy: 0.7048 \n",
      "Epoch 21: val_loss did not improve from 3.20403\n",
      "7/7 [==============================] - 146s 20s/step - loss: 0.8194 - accuracy: 0.7048 - val_loss: 4.6864 - val_accuracy: 0.2807\n",
      "Epoch 22/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7081 - accuracy: 0.7619 \n",
      "Epoch 22: val_loss did not improve from 3.20403\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.7081 - accuracy: 0.7619 - val_loss: 3.8860 - val_accuracy: 0.3158\n",
      "Epoch 23/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7024 - accuracy: 0.7619 \n",
      "Epoch 23: val_loss improved from 3.20403 to 2.69553, saving model to C:\\Users\\soumi\\OneDrive\\Desktop\\Inceptionv3\\Inc23-0.4386.hdf5\n",
      "7/7 [==============================] - 144s 20s/step - loss: 0.7024 - accuracy: 0.7619 - val_loss: 2.6955 - val_accuracy: 0.4386\n",
      "Epoch 24/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8021 - accuracy: 0.7143 \n",
      "Epoch 24: val_loss did not improve from 2.69553\n",
      "7/7 [==============================] - 140s 20s/step - loss: 0.8021 - accuracy: 0.7143 - val_loss: 10.6625 - val_accuracy: 0.3158\n",
      "Epoch 25/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7567 - accuracy: 0.7095 \n",
      "Epoch 25: val_loss did not improve from 2.69553\n",
      "7/7 [==============================] - 237s 36s/step - loss: 0.7567 - accuracy: 0.7095 - val_loss: 4.7854 - val_accuracy: 0.4211\n",
      "Epoch 26/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7472 - accuracy: 0.7238 \n",
      "Epoch 26: val_loss did not improve from 2.69553\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.7472 - accuracy: 0.7238 - val_loss: 4.5590 - val_accuracy: 0.3684\n",
      "Epoch 27/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8348 - accuracy: 0.7048 \n",
      "Epoch 27: val_loss did not improve from 2.69553\n",
      "7/7 [==============================] - 141s 20s/step - loss: 0.8348 - accuracy: 0.7048 - val_loss: 4.5925 - val_accuracy: 0.4211\n",
      "Epoch 28/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.9724 - accuracy: 0.6333 \n",
      "Epoch 28: val_loss did not improve from 2.69553\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.9724 - accuracy: 0.6333 - val_loss: 5.8848 - val_accuracy: 0.4035\n",
      "Epoch 29/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7781 - accuracy: 0.7619 \n",
      "Epoch 29: val_loss improved from 2.69553 to 2.49390, saving model to C:\\Users\\soumi\\OneDrive\\Desktop\\Inceptionv3\\Inc29-0.3509.hdf5\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.7781 - accuracy: 0.7619 - val_loss: 2.4939 - val_accuracy: 0.3509\n",
      "Epoch 30/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7957 - accuracy: 0.7143 \n",
      "Epoch 30: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.7957 - accuracy: 0.7143 - val_loss: 3.0966 - val_accuracy: 0.3333\n",
      "Epoch 31/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7337 - accuracy: 0.7381 \n",
      "Epoch 31: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.7337 - accuracy: 0.7381 - val_loss: 6.1777 - val_accuracy: 0.1404\n",
      "Epoch 32/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6874 - accuracy: 0.7333 \n",
      "Epoch 32: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 146s 20s/step - loss: 0.6874 - accuracy: 0.7333 - val_loss: 4.6867 - val_accuracy: 0.2632\n",
      "Epoch 33/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6557 - accuracy: 0.7524 \n",
      "Epoch 33: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 147s 20s/step - loss: 0.6557 - accuracy: 0.7524 - val_loss: 4.1419 - val_accuracy: 0.3684\n",
      "Epoch 34/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7215 - accuracy: 0.7476 \n",
      "Epoch 34: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 156s 21s/step - loss: 0.7215 - accuracy: 0.7476 - val_loss: 4.9322 - val_accuracy: 0.3684\n",
      "Epoch 35/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7415 - accuracy: 0.7476 \n",
      "Epoch 35: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.7415 - accuracy: 0.7476 - val_loss: 5.6182 - val_accuracy: 0.2982\n",
      "Epoch 36/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5242 - accuracy: 0.8048 \n",
      "Epoch 36: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.5242 - accuracy: 0.8048 - val_loss: 8.3173 - val_accuracy: 0.1579\n",
      "Epoch 37/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6277 - accuracy: 0.7667 \n",
      "Epoch 37: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.6277 - accuracy: 0.7667 - val_loss: 6.5252 - val_accuracy: 0.1930\n",
      "Epoch 38/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5960 - accuracy: 0.7952 \n",
      "Epoch 38: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 144s 20s/step - loss: 0.5960 - accuracy: 0.7952 - val_loss: 5.1955 - val_accuracy: 0.1930\n",
      "Epoch 39/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.8190 \n",
      "Epoch 39: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.5301 - accuracy: 0.8190 - val_loss: 4.2806 - val_accuracy: 0.3158\n",
      "Epoch 40/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.8190 \n",
      "Epoch 40: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.5820 - accuracy: 0.8190 - val_loss: 4.5612 - val_accuracy: 0.2632\n",
      "Epoch 41/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.8476 \n",
      "Epoch 41: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 144s 20s/step - loss: 0.4532 - accuracy: 0.8476 - val_loss: 3.9094 - val_accuracy: 0.3333\n",
      "Epoch 42/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.7952 \n",
      "Epoch 42: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 19s/step - loss: 0.5978 - accuracy: 0.7952 - val_loss: 3.2464 - val_accuracy: 0.3860\n",
      "Epoch 43/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.8381 \n",
      "Epoch 43: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.5169 - accuracy: 0.8381 - val_loss: 3.9471 - val_accuracy: 0.4211\n",
      "Epoch 44/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.8238 \n",
      "Epoch 44: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.4675 - accuracy: 0.8238 - val_loss: 2.9089 - val_accuracy: 0.4211\n",
      "Epoch 45/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6089 - accuracy: 0.7857 \n",
      "Epoch 45: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 149s 21s/step - loss: 0.6089 - accuracy: 0.7857 - val_loss: 4.4624 - val_accuracy: 0.4561\n",
      "Epoch 46/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6154 - accuracy: 0.7714 \n",
      "Epoch 46: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 154s 21s/step - loss: 0.6154 - accuracy: 0.7714 - val_loss: 4.4939 - val_accuracy: 0.4211\n",
      "Epoch 47/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.8143 \n",
      "Epoch 47: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 148s 20s/step - loss: 0.5450 - accuracy: 0.8143 - val_loss: 4.5675 - val_accuracy: 0.3158\n",
      "Epoch 48/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.7905 \n",
      "Epoch 48: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.5363 - accuracy: 0.7905 - val_loss: 5.0210 - val_accuracy: 0.4737\n",
      "Epoch 49/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.8381 \n",
      "Epoch 49: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 20s/step - loss: 0.4426 - accuracy: 0.8381 - val_loss: 6.2812 - val_accuracy: 0.4035\n",
      "Epoch 50/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.8762 \n",
      "Epoch 50: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.4597 - accuracy: 0.8762 - val_loss: 8.9234 - val_accuracy: 0.4211\n",
      "Epoch 51/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.8095 \n",
      "Epoch 51: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 20s/step - loss: 0.6837 - accuracy: 0.8095 - val_loss: 4.1911 - val_accuracy: 0.4035\n",
      "Epoch 52/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.8190 \n",
      "Epoch 52: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.6188 - accuracy: 0.8190 - val_loss: 3.6593 - val_accuracy: 0.4211\n",
      "Epoch 53/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.8286 \n",
      "Epoch 53: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 20s/step - loss: 0.5259 - accuracy: 0.8286 - val_loss: 2.9853 - val_accuracy: 0.4561\n",
      "Epoch 54/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.8000 \n",
      "Epoch 54: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 138s 19s/step - loss: 0.5017 - accuracy: 0.8000 - val_loss: 4.3128 - val_accuracy: 0.3333\n",
      "Epoch 55/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3564 - accuracy: 0.8952 \n",
      "Epoch 55: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.3564 - accuracy: 0.8952 - val_loss: 4.4213 - val_accuracy: 0.3333\n",
      "Epoch 56/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3996 - accuracy: 0.8571 \n",
      "Epoch 56: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 137s 19s/step - loss: 0.3996 - accuracy: 0.8571 - val_loss: 4.3101 - val_accuracy: 0.3158\n",
      "Epoch 57/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.8714 \n",
      "Epoch 57: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.3572 - accuracy: 0.8714 - val_loss: 4.6484 - val_accuracy: 0.3333\n",
      "Epoch 58/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3783 - accuracy: 0.8524 \n",
      "Epoch 58: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 19s/step - loss: 0.3783 - accuracy: 0.8524 - val_loss: 4.9055 - val_accuracy: 0.4386\n",
      "Epoch 59/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3771 - accuracy: 0.8714 \n",
      "Epoch 59: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 20s/step - loss: 0.3771 - accuracy: 0.8714 - val_loss: 4.3369 - val_accuracy: 0.4211\n",
      "Epoch 60/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8714 \n",
      "Epoch 60: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.4135 - accuracy: 0.8714 - val_loss: 4.8131 - val_accuracy: 0.2456\n",
      "Epoch 61/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.8714 \n",
      "Epoch 61: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.3781 - accuracy: 0.8714 - val_loss: 5.4613 - val_accuracy: 0.3333\n",
      "Epoch 62/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.8714 \n",
      "Epoch 62: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 138s 19s/step - loss: 0.3636 - accuracy: 0.8714 - val_loss: 5.8481 - val_accuracy: 0.2632\n",
      "Epoch 63/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.9000 \n",
      "Epoch 63: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 138s 19s/step - loss: 0.3186 - accuracy: 0.9000 - val_loss: 4.7630 - val_accuracy: 0.3158\n",
      "Epoch 64/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4653 - accuracy: 0.8429 \n",
      "Epoch 64: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 19s/step - loss: 0.4653 - accuracy: 0.8429 - val_loss: 6.2341 - val_accuracy: 0.3333\n",
      "Epoch 65/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.8095 \n",
      "Epoch 65: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 138s 19s/step - loss: 0.5499 - accuracy: 0.8095 - val_loss: 6.8432 - val_accuracy: 0.3860\n",
      "Epoch 66/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.9238 \n",
      "Epoch 66: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 20s/step - loss: 0.2948 - accuracy: 0.9238 - val_loss: 6.3469 - val_accuracy: 0.2982\n",
      "Epoch 67/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.8905 \n",
      "Epoch 67: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.3609 - accuracy: 0.8905 - val_loss: 4.8542 - val_accuracy: 0.2982\n",
      "Epoch 68/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8810 \n",
      "Epoch 68: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.3912 - accuracy: 0.8810 - val_loss: 4.4209 - val_accuracy: 0.3684\n",
      "Epoch 69/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.8762 \n",
      "Epoch 69: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.3664 - accuracy: 0.8762 - val_loss: 3.4825 - val_accuracy: 0.3509\n",
      "Epoch 70/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8524 \n",
      "Epoch 70: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.3812 - accuracy: 0.8524 - val_loss: 5.8813 - val_accuracy: 0.3333\n",
      "Epoch 71/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.9143 \n",
      "Epoch 71: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 137s 19s/step - loss: 0.2781 - accuracy: 0.9143 - val_loss: 6.2965 - val_accuracy: 0.3509\n",
      "Epoch 72/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.9429 \n",
      "Epoch 72: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.2286 - accuracy: 0.9429 - val_loss: 5.3024 - val_accuracy: 0.2982\n",
      "Epoch 73/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.8810 \n",
      "Epoch 73: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.3518 - accuracy: 0.8810 - val_loss: 4.6496 - val_accuracy: 0.3158\n",
      "Epoch 74/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3217 - accuracy: 0.8619 \n",
      "Epoch 74: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 138s 19s/step - loss: 0.3217 - accuracy: 0.8619 - val_loss: 5.5689 - val_accuracy: 0.3158\n",
      "Epoch 75/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.8667 \n",
      "Epoch 75: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.3520 - accuracy: 0.8667 - val_loss: 6.8436 - val_accuracy: 0.3509\n",
      "Epoch 76/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.9190 \n",
      "Epoch 76: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.2733 - accuracy: 0.9190 - val_loss: 8.4231 - val_accuracy: 0.3333\n",
      "Epoch 77/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9238 \n",
      "Epoch 77: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.2322 - accuracy: 0.9238 - val_loss: 7.1175 - val_accuracy: 0.4386\n",
      "Epoch 78/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4082 - accuracy: 0.8905 \n",
      "Epoch 78: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 137s 19s/step - loss: 0.4082 - accuracy: 0.8905 - val_loss: 3.6418 - val_accuracy: 0.4737\n",
      "Epoch 79/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.8619 \n",
      "Epoch 79: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.4426 - accuracy: 0.8619 - val_loss: 6.9557 - val_accuracy: 0.3509\n",
      "Epoch 80/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3185 - accuracy: 0.9000 \n",
      "Epoch 80: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 139s 19s/step - loss: 0.3185 - accuracy: 0.9000 - val_loss: 10.4485 - val_accuracy: 0.2632\n",
      "Epoch 81/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.9190 \n",
      "Epoch 81: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.3468 - accuracy: 0.9190 - val_loss: 3.7630 - val_accuracy: 0.4386\n",
      "Epoch 82/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.9190 \n",
      "Epoch 82: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.2776 - accuracy: 0.9190 - val_loss: 3.2093 - val_accuracy: 0.5088\n",
      "Epoch 83/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3578 - accuracy: 0.8857 \n",
      "Epoch 83: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.3578 - accuracy: 0.8857 - val_loss: 8.7184 - val_accuracy: 0.4035\n",
      "Epoch 84/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.8381 \n",
      "Epoch 84: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 135s 19s/step - loss: 0.5054 - accuracy: 0.8381 - val_loss: 5.3446 - val_accuracy: 0.2982\n",
      "Epoch 85/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9381 \n",
      "Epoch 85: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 138s 19s/step - loss: 0.2834 - accuracy: 0.9381 - val_loss: 8.3324 - val_accuracy: 0.2632\n",
      "Epoch 86/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.8667 \n",
      "Epoch 86: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.3411 - accuracy: 0.8667 - val_loss: 5.2865 - val_accuracy: 0.2105\n",
      "Epoch 87/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.9381 \n",
      "Epoch 87: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 137s 19s/step - loss: 0.1780 - accuracy: 0.9381 - val_loss: 4.7796 - val_accuracy: 0.1930\n",
      "Epoch 88/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9381 \n",
      "Epoch 88: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 150s 21s/step - loss: 0.1806 - accuracy: 0.9381 - val_loss: 7.0105 - val_accuracy: 0.1754\n",
      "Epoch 89/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9476 \n",
      "Epoch 89: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.1633 - accuracy: 0.9476 - val_loss: 6.0991 - val_accuracy: 0.2982\n",
      "Epoch 90/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9857 \n",
      "Epoch 90: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 183s 25s/step - loss: 0.0544 - accuracy: 0.9857 - val_loss: 4.1420 - val_accuracy: 0.3860\n",
      "Epoch 91/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9762 \n",
      "Epoch 91: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.0998 - accuracy: 0.9762 - val_loss: 4.8074 - val_accuracy: 0.4035\n",
      "Epoch 92/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9667 \n",
      "Epoch 92: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.1249 - accuracy: 0.9667 - val_loss: 5.0599 - val_accuracy: 0.4561\n",
      "Epoch 93/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9667 \n",
      "Epoch 93: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.1018 - accuracy: 0.9667 - val_loss: 5.8513 - val_accuracy: 0.4912\n",
      "Epoch 94/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9667 \n",
      "Epoch 94: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 180s 25s/step - loss: 0.1311 - accuracy: 0.9667 - val_loss: 4.4281 - val_accuracy: 0.3509\n",
      "Epoch 95/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.9238 \n",
      "Epoch 95: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.2619 - accuracy: 0.9238 - val_loss: 4.5779 - val_accuracy: 0.2632\n",
      "Epoch 96/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.9476 \n",
      "Epoch 96: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 182s 25s/step - loss: 0.2373 - accuracy: 0.9476 - val_loss: 8.5740 - val_accuracy: 0.3158\n",
      "Epoch 97/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9333 \n",
      "Epoch 97: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 182s 25s/step - loss: 0.1616 - accuracy: 0.9333 - val_loss: 4.8834 - val_accuracy: 0.3860\n",
      "Epoch 98/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.9524 \n",
      "Epoch 98: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.1452 - accuracy: 0.9524 - val_loss: 3.9325 - val_accuracy: 0.3684\n",
      "Epoch 99/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9476 \n",
      "Epoch 99: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 183s 25s/step - loss: 0.2171 - accuracy: 0.9476 - val_loss: 3.1691 - val_accuracy: 0.5263\n",
      "Epoch 100/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2527 - accuracy: 0.9000 \n",
      "Epoch 100: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.2527 - accuracy: 0.9000 - val_loss: 4.1640 - val_accuracy: 0.4386\n",
      "Epoch 101/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.9238 \n",
      "Epoch 101: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.1976 - accuracy: 0.9238 - val_loss: 4.8788 - val_accuracy: 0.3509\n",
      "Epoch 102/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.9333 \n",
      "Epoch 102: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 179s 25s/step - loss: 0.2092 - accuracy: 0.9333 - val_loss: 5.6169 - val_accuracy: 0.3509\n",
      "Epoch 103/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 0.9667 \n",
      "Epoch 103: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.1324 - accuracy: 0.9667 - val_loss: 6.8388 - val_accuracy: 0.1404\n",
      "Epoch 104/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9429 \n",
      "Epoch 104: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 181s 25s/step - loss: 0.2284 - accuracy: 0.9429 - val_loss: 4.6978 - val_accuracy: 0.3158\n",
      "Epoch 105/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9619 \n",
      "Epoch 105: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 145s 19s/step - loss: 0.1402 - accuracy: 0.9619 - val_loss: 4.2029 - val_accuracy: 0.3684\n",
      "Epoch 106/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.9524 \n",
      "Epoch 106: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 136s 19s/step - loss: 0.1486 - accuracy: 0.9524 - val_loss: 3.7188 - val_accuracy: 0.4211\n",
      "Epoch 107/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9810 \n",
      "Epoch 107: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.0924 - accuracy: 0.9810 - val_loss: 6.1606 - val_accuracy: 0.3860\n",
      "Epoch 108/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9429 \n",
      "Epoch 108: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 146s 20s/step - loss: 0.2087 - accuracy: 0.9429 - val_loss: 5.4610 - val_accuracy: 0.3333\n",
      "Epoch 109/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9762 \n",
      "Epoch 109: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 148s 20s/step - loss: 0.0923 - accuracy: 0.9762 - val_loss: 4.6236 - val_accuracy: 0.4035\n",
      "Epoch 110/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9524 \n",
      "Epoch 110: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 144s 20s/step - loss: 0.1083 - accuracy: 0.9524 - val_loss: 3.9657 - val_accuracy: 0.3333\n",
      "Epoch 111/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9476 \n",
      "Epoch 111: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.1312 - accuracy: 0.9476 - val_loss: 6.3496 - val_accuracy: 0.2281\n",
      "Epoch 112/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9762 \n",
      "Epoch 112: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.0996 - accuracy: 0.9762 - val_loss: 9.4665 - val_accuracy: 0.3333\n",
      "Epoch 113/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9238 \n",
      "Epoch 113: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 19s/step - loss: 0.2139 - accuracy: 0.9238 - val_loss: 6.3786 - val_accuracy: 0.3158\n",
      "Epoch 114/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.9048 \n",
      "Epoch 114: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 20s/step - loss: 0.2490 - accuracy: 0.9048 - val_loss: 5.6676 - val_accuracy: 0.4561\n",
      "Epoch 115/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2604 - accuracy: 0.9333 \n",
      "Epoch 115: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.2604 - accuracy: 0.9333 - val_loss: 7.5445 - val_accuracy: 0.4035\n",
      "Epoch 116/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.8810 \n",
      "Epoch 116: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 144s 20s/step - loss: 0.3244 - accuracy: 0.8810 - val_loss: 9.0333 - val_accuracy: 0.3158\n",
      "Epoch 117/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9238 \n",
      "Epoch 117: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.2344 - accuracy: 0.9238 - val_loss: 5.4226 - val_accuracy: 0.4561\n",
      "Epoch 118/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9000 \n",
      "Epoch 118: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.2665 - accuracy: 0.9000 - val_loss: 6.0992 - val_accuracy: 0.5088\n",
      "Epoch 119/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2439 - accuracy: 0.9143 \n",
      "Epoch 119: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 144s 20s/step - loss: 0.2439 - accuracy: 0.9143 - val_loss: 6.6259 - val_accuracy: 0.4386\n",
      "Epoch 120/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9429 \n",
      "Epoch 120: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.1877 - accuracy: 0.9429 - val_loss: 4.5557 - val_accuracy: 0.5088\n",
      "Epoch 121/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.9571 \n",
      "Epoch 121: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 20s/step - loss: 0.1302 - accuracy: 0.9571 - val_loss: 4.7565 - val_accuracy: 0.4386\n",
      "Epoch 122/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.9524 \n",
      "Epoch 122: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 140s 19s/step - loss: 0.1556 - accuracy: 0.9524 - val_loss: 5.6455 - val_accuracy: 0.3509\n",
      "Epoch 123/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9571 \n",
      "Epoch 123: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.0957 - accuracy: 0.9571 - val_loss: 5.1844 - val_accuracy: 0.4035\n",
      "Epoch 124/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9619 \n",
      "Epoch 124: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.0860 - accuracy: 0.9619 - val_loss: 4.5322 - val_accuracy: 0.3684\n",
      "Epoch 125/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9619 \n",
      "Epoch 125: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.1139 - accuracy: 0.9619 - val_loss: 4.1443 - val_accuracy: 0.3684\n",
      "Epoch 126/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 1.0000 \n",
      "Epoch 126: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 4.6264 - val_accuracy: 0.3509\n",
      "Epoch 127/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9905 \n",
      "Epoch 127: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 19s/step - loss: 0.0467 - accuracy: 0.9905 - val_loss: 4.2259 - val_accuracy: 0.3158\n",
      "Epoch 128/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9810 \n",
      "Epoch 128: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 145s 20s/step - loss: 0.0685 - accuracy: 0.9810 - val_loss: 4.9988 - val_accuracy: 0.2982\n",
      "Epoch 129/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9810 \n",
      "Epoch 129: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 144s 20s/step - loss: 0.0786 - accuracy: 0.9810 - val_loss: 4.7731 - val_accuracy: 0.3333\n",
      "Epoch 130/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9952 \n",
      "Epoch 130: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.0405 - accuracy: 0.9952 - val_loss: 4.2117 - val_accuracy: 0.2982\n",
      "Epoch 131/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9905 \n",
      "Epoch 131: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 144s 20s/step - loss: 0.0382 - accuracy: 0.9905 - val_loss: 4.2390 - val_accuracy: 0.3684\n",
      "Epoch 132/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9857 \n",
      "Epoch 132: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.0252 - accuracy: 0.9857 - val_loss: 3.1964 - val_accuracy: 0.4211\n",
      "Epoch 133/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9810 \n",
      "Epoch 133: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.0547 - accuracy: 0.9810 - val_loss: 4.5604 - val_accuracy: 0.3684\n",
      "Epoch 134/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9762 \n",
      "Epoch 134: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.0737 - accuracy: 0.9762 - val_loss: 4.1006 - val_accuracy: 0.4211\n",
      "Epoch 135/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9429 \n",
      "Epoch 135: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 20s/step - loss: 0.1611 - accuracy: 0.9429 - val_loss: 3.6069 - val_accuracy: 0.5088\n",
      "Epoch 136/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9667 \n",
      "Epoch 136: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 144s 20s/step - loss: 0.1226 - accuracy: 0.9667 - val_loss: 6.9605 - val_accuracy: 0.3684\n",
      "Epoch 137/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.9476 \n",
      "Epoch 137: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 141s 19s/step - loss: 0.1787 - accuracy: 0.9476 - val_loss: 5.7682 - val_accuracy: 0.3860\n",
      "Epoch 138/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9619 \n",
      "Epoch 138: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 145s 20s/step - loss: 0.1117 - accuracy: 0.9619 - val_loss: 5.6491 - val_accuracy: 0.3684\n",
      "Epoch 139/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9857 \n",
      "Epoch 139: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 149s 21s/step - loss: 0.0561 - accuracy: 0.9857 - val_loss: 7.7245 - val_accuracy: 0.3860\n",
      "Epoch 140/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9905 \n",
      "Epoch 140: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 148s 21s/step - loss: 0.0544 - accuracy: 0.9905 - val_loss: 9.9337 - val_accuracy: 0.3509\n",
      "Epoch 141/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9857 \n",
      "Epoch 141: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 149s 21s/step - loss: 0.0371 - accuracy: 0.9857 - val_loss: 7.4865 - val_accuracy: 0.3158\n",
      "Epoch 142/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1666 - accuracy: 0.9619 \n",
      "Epoch 142: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 146s 20s/step - loss: 0.1666 - accuracy: 0.9619 - val_loss: 5.7555 - val_accuracy: 0.4035\n",
      "Epoch 143/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9286 \n",
      "Epoch 143: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.1720 - accuracy: 0.9286 - val_loss: 5.2100 - val_accuracy: 0.4211\n",
      "Epoch 144/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.9333 \n",
      "Epoch 144: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 145s 20s/step - loss: 0.1901 - accuracy: 0.9333 - val_loss: 4.1977 - val_accuracy: 0.4386\n",
      "Epoch 145/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.9381 \n",
      "Epoch 145: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.1971 - accuracy: 0.9381 - val_loss: 6.1532 - val_accuracy: 0.2982\n",
      "Epoch 146/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9714 \n",
      "Epoch 146: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 145s 20s/step - loss: 0.1030 - accuracy: 0.9714 - val_loss: 8.2644 - val_accuracy: 0.1228\n",
      "Epoch 147/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9381 \n",
      "Epoch 147: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 143s 20s/step - loss: 0.1885 - accuracy: 0.9381 - val_loss: 7.4710 - val_accuracy: 0.2456\n",
      "Epoch 148/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9333 \n",
      "Epoch 148: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 146s 20s/step - loss: 0.1990 - accuracy: 0.9333 - val_loss: 4.7621 - val_accuracy: 0.3509\n",
      "Epoch 149/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9714 \n",
      "Epoch 149: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 142s 20s/step - loss: 0.0806 - accuracy: 0.9714 - val_loss: 3.7663 - val_accuracy: 0.4211\n",
      "Epoch 150/150\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9905 \n",
      "Epoch 150: val_loss did not improve from 2.49390\n",
      "7/7 [==============================] - 144s 20s/step - loss: 0.0755 - accuracy: 0.9905 - val_loss: 4.3960 - val_accuracy: 0.4211\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "history=model.fit(\n",
    "    training_set, \n",
    "    epochs=150, \n",
    "    validation_data=test_set,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb128bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model,load_model\n",
    "model=load_model(r\"C:\\Users\\soumi\\OneDrive\\Desktop\\Inceptionv3\\Inc29-0.3509.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b077f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]], shape=(57, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([57, 10])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar=np.empty(0)\n",
    "for im,y in test_set:\n",
    "    ar=np.append(ar,y)\n",
    "yt=np.zeros((57,10))\n",
    "count=0\n",
    "for i in range(0,57):\n",
    "    for j in range(5):\n",
    "        yt[i][j]=ar[count]\n",
    "        count+=1\n",
    "yt=tf.convert_to_tensor(yt,dtype=tf.float32)\n",
    "print(yt)\n",
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8e277cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 6s 2s/step\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp=model.predict(test_set)\n",
    "arr=np.zeros(yp.shape)\n",
    "for i in range(yp.shape[0]):\n",
    "    for j in range(yp.shape[1]):\n",
    "        c=yp[i].argmax()\n",
    "        arr[i][c]=1\n",
    "yp=arr\n",
    "print(yp)\n",
    "yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24d24388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.017543859649122806\n",
      "Precision= 0.01\n",
      "Recall= 0.014285714285714285\n",
      "F1 Score= 0.011764705882352941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soumi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\soumi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\soumi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(yt,yp)\n",
    "print('Accuracy=',accuracy)\n",
    "precision=precision_score(yt,yp,average='macro')\n",
    "print('Precision=',precision)\n",
    "recall=recall_score(yt,yp,average='macro')\n",
    "print('Recall=',recall)\n",
    "f1=f1_score(yt,yp,average='macro')\n",
    "print('F1 Score=',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "694ce004",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af1e32d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Train acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Test acc')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Train loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Test loss')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image=tf.keras.utils.load_img(r'C:\\Users\\ritan\\Desktop\\Maths for ML\\Groundnut FD\\Images for checking\\img.jpg',target_size=(224,224))\n",
    "test_image=tf.keras.utils.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=model.predict(test_image)\n",
    "result=result.flatten()\n",
    "print(result)\n",
    "print(class_names)\n",
    "index=result.argmax()\n",
    "confidence=result[index]*100;\n",
    "pred_class=class_names[index]\n",
    "if pred_class!='Groundnut__Healthy':\n",
    "    print(f'The disease of the given groundnut leaf is {pred_class} predicted with {confidence} % confidence')\n",
    "else:\n",
    "    print(f'The groundnut leaf is healthy predicted with {confidence} % confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68f557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
